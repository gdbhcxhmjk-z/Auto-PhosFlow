#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import time
import csv
import glob
import requests  # <--- éœ€è¦å®‰è£…
import traceback
from pathlib import Path
from datetime import datetime, timedelta

# å¼•å…¥æ ¸å¿ƒå·¥ä½œæµç±»
from workflow_manager import MoleculeFlow

# ================= é…ç½®åŒºåŸŸ =================
SOURCE_DIR = Path("molecules")       # åˆ†å­æºç›®å½•
RESULTS_DIR = Path("results")        # ç»“æœç›®å½•
STATUS_FILE = Path("status_report.csv") # è¿›åº¦è®°å½•æ–‡ä»¶

MAX_CONCURRENT = 10                  # å¹¶è¡Œåº¦
CHECK_INTERVAL = 300                 # è½®è¯¢é—´éš” (ç§’)

# --- æŠ¥è­¦é…ç½® (é£ä¹¦) ---
ENABLE_ALERT = True
# æ›¿æ¢ä¸ºä½ çš„é£ä¹¦ Webhook åœ°å€
WEBHOOK_URL = "https://open.feishu.cn/open-apis/bot/v2/hook/8295e851-d6ae-4eba-bb08-4ba2cd1579e3"
TIMEOUT_THRESHOLD_HOURS = 48         # è¶…æ—¶é˜ˆå€¼ (å°æ—¶)
# ===========================================

class BatchController:
    def __init__(self):
        self.db = {} 
        self._load_db()
        
        SOURCE_DIR.mkdir(exist_ok=True)
        RESULTS_DIR.mkdir(exist_ok=True)

    def _load_db(self):
        if not STATUS_FILE.exists():
            self._init_csv()
            return
        with open(STATUS_FILE, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                self.db[row['Name']] = row

    def _init_csv(self):
        with open(STATUS_FILE, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['Name', 'Status', 'Current_Stage', 'Last_Updated', 'Remark'])

    def _save_db(self):
        with open(STATUS_FILE, 'w', encoding='utf-8', newline='') as f:
            headers = ['Name', 'Status', 'Current_Stage', 'Last_Updated', 'Remark']
            writer = csv.DictWriter(f, fieldnames=headers)
            writer.writeheader()
            for name in sorted(self.db.keys()):
                writer.writerow(self.db[name])

    def log(self, message):
        """[æ–°å¢] ç»Ÿä¸€æ—¥å¿—è¾“å‡ºæ ¼å¼ï¼Œå¸¦æ—¶é—´æˆ³"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] {message}", flush=True) # flush=True ç¡®ä¿å®æ—¶å†™å…¥æ–‡ä»¶

    # === æ ¸å¿ƒï¼šé£ä¹¦æŠ¥è­¦å‡½æ•° ===
    def send_feishu_alert(self, title, message):
        """
        å‘é€é£ä¹¦æŠ¥è­¦ã€‚
        æ³¨æ„ï¼šå†…å®¹ä¸­å¿…é¡»åŒ…å«å…³é”®è¯ 'Alert' æ‰èƒ½é€šè¿‡å®‰å…¨æ ¡éªŒã€‚
        """
        if not ENABLE_ALERT: return
        
        print(f"  [ALERT] {title}: {message}")
        
        # æ„é€ ç¬¦åˆé£ä¹¦è¦æ±‚çš„æ–‡æœ¬ (å¿…é¡»åŒ…å« Alert)
        full_text = f"ğŸš¨ [Auto-PhosFlow Alert]\n**{title}**\n----------------\n{message}\n\næ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        
        data = {
            "msg_type": "text",
            "content": {
                "text": full_text
            }
        }
        
        try:
            resp = requests.post(WEBHOOK_URL, json=data, timeout=10)
            if resp.status_code != 200:
                print(f"  [Error] Feishu API returned {resp.status_code}: {resp.text}")
        except Exception as e:
            print(f"  [Error] Failed to send Feishu webhook: {e}")

    def scan_new_molecules(self):
        xyz_files = glob.glob(str(SOURCE_DIR / "*.xyz"))
        new_count = 0
        for p in xyz_files:
            name = Path(p).stem
            if name not in self.db:
                self.db[name] = {
                    'Name': name,
                    'Status': 'PENDING',
                    'Current_Stage': 'Init',
                    'Last_Updated': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'Remark': 'Newly added'
                }
                new_count += 1
        
        if new_count > 0:
            print(f"  [Scanner] Found {new_count} new molecules.")
            self._save_db()

    def determine_stage(self, flow):
        if (flow.root / "REPORT_PLQY.txt").exists(): return "Analysis Done"
        if (flow.dirs['kic'] / "job.done").exists(): return "MOMAP Kic Done"
        if (flow.dirs['kisc'] / "job.done").exists(): return "MOMAP Kisc Done"
        if (flow.dirs['kr'] / "job.done").exists(): return "MOMAP Kr Done"
        if (flow.dirs['orca'] / "job.done").exists(): return "ORCA Done"
        if (flow.dirs['t1_opt'] / "job.done").exists(): return "Gaussian T1 Done"
        if (flow.dirs['s1_opt'] / "job.done").exists(): return "Gaussian S1 Done"
        if (flow.dirs['s0_freq'] / "job.done").exists(): return "Gaussian S0 Done"
        return "Starting / In Progress"

    def run_watchdog(self):
        """çœ‹é—¨ç‹—ï¼šæ£€æŸ¥è¶…æ—¶ä»»åŠ¡"""
        print("  [Watchdog] Checking task health...")
        now = datetime.now()
        
        for name, data in self.db.items():
            if data['Status'] == 'RUNNING':
                try:
                    last_update = datetime.strptime(data['Last_Updated'], "%Y-%m-%d %H:%M:%S")
                    delta = now - last_update
                    hours_running = delta.total_seconds() / 3600
                    
                    # å¦‚æœè¿è¡Œæ—¶é—´è¶…è¿‡é˜ˆå€¼ï¼Œä¸”ä¹‹å‰æ²¡æœ‰æŠ¥è¿‡è­¦ï¼ˆé¿å…åˆ·å±ï¼Œè¿™é‡Œç®€å•ç”¨ Remark åˆ¤æ–­ï¼‰
                    if hours_running > TIMEOUT_THRESHOLD_HOURS:
                        if "Timeout Alert Sent" not in data['Remark']:
                            msg = f"åˆ†å­ {name} å·²å¡ä½ {hours_running:.1f} å°æ—¶ã€‚\nå½“å‰é˜¶æ®µ: {data['Current_Stage']}"
                            self.send_feishu_alert("ä»»åŠ¡è¶…æ—¶è­¦å‘Š (Timeout)", msg)
                            
                            # æ ‡è®°å·²æŠ¥è­¦ï¼Œé˜²æ­¢ä¸‹æ¬¡å¾ªç¯é‡å¤å‘
                            self.db[name]['Remark'] += " [Timeout Alert Sent]"
                except:
                    pass

    def run_cycle(self):
        print(f"\n[{datetime.now().strftime('%H:%M:%S')}] === Starting Schedule Cycle ===")
        
        self.scan_new_molecules()
        
        running_jobs = [name for name, data in self.db.items() if data['Status'] == 'RUNNING']
        self.log(f"[Status] Active Jobs: {len(running_jobs)} / Limit: {MAX_CONCURRENT}")

        # å¡«è¡¥ç©ºç¼º
        slots_available = MAX_CONCURRENT - len(running_jobs)
        if slots_available > 0:
            pending_mols = [name for name, data in self.db.items() if data['Status'] == 'PENDING']
            to_activate = pending_mols[:slots_available]
            for name in to_activate:
                self.db[name]['Status'] = 'RUNNING'
                self.db[name]['Remark'] = 'Activated'
                print(f"  [Activate] Molecule '{name}' moved to RUNNING queue.")
            running_jobs.extend(to_activate)

        if not running_jobs:
            print("  [Idle] No active tasks. Waiting for new files...")
            return

        for name in running_jobs:
            xyz_path = SOURCE_DIR / f"{name}.xyz"
            
            # [ä¿®æ”¹] å¢åŠ å¤„ç†å½“å‰åˆ†å­çš„æ—¥å¿—
            # print(f"  Processing {name}...") 
            
            if not xyz_path.exists():
                msg = f"æºæ–‡ä»¶ä¸¢å¤±: {name}.xyz"
                self.log(f"[Error] {msg}")  # <--- è®°å½•åˆ° Log
                self.db[name]['Status'] = 'FAILED'
                self.db[name]['Remark'] = 'XYZ Missing'
                self.send_feishu_alert("æ–‡ä»¶ä¸¢å¤±é”™è¯¯", msg)
                continue

            try:
                flow = MoleculeFlow(name, xyz_path, RESULTS_DIR)
                
                # æ£€æŸ¥è‡´å‘½é”™è¯¯
                if flow._is_failed():
                     if self.db[name]['Status'] != 'FAILED': # é˜²æ­¢é‡å¤æ‰“å°
                         self.log(f"[Stop] Molecule {name} has FATAL ERROR. Skipping.")
                     self.db[name]['Status'] = 'FAILED'
                     self.db[name]['Remark'] = 'Fatal Error (See Log)'
                
                # æ£€æŸ¥å®Œæˆ
                elif (flow.root / "REPORT_PLQY.txt").exists():
                    if self.db[name]['Status'] != 'COMPLETED':
                        self.log(f"[Done] Molecule {name} Analysis Completed!")
                    self.db[name]['Status'] = 'COMPLETED'
                    self.db[name]['Current_Stage'] = 'Finished'
                    self.db[name]['Remark'] = 'PLQY Report Generated'
                
                else:
                    # æ­£å¸¸æ¨è¿›
                    # è¿™é‡Œä¸éœ€è¦é¢å¤– printï¼Œå› ä¸º workflow_manager.py é‡Œçš„ _submit_to_queue ä¼šæ‰“å°æäº¤ä¿¡æ¯
                    flow.process()
                    
                    current_stage = self.determine_stage(flow)
                    self.db[name]['Current_Stage'] = current_stage
                    self.db[name]['Remark'] = 'Processing'

            except Exception as e:
                err_msg = f"æœªæ•è·å¼‚å¸¸: {str(e)}"
                self.log(f"[Exception] {name}: {err_msg}") # <--- è®°å½•è¯¦ç»†æŠ¥é”™åˆ° Log
                traceback.print_exc() # æ‰“å°å †æ ˆä¿¡æ¯
                
                self.db[name]['Status'] = 'ERROR'
                self.db[name]['Remark'] = str(e)[:50]
                self.send_feishu_alert(f"ç¨‹åºå´©æºƒ: {name}", err_msg)

            self.db[name]['Last_Updated'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        self._save_db()
        self.run_watchdog()
        print(f"  [Cycle] Finished.")

if __name__ == "__main__":
    controller = BatchController()
    
    print(f"ğŸš€ Auto-PhosFlow Batch Manager Started.")
    print(f"   Webhook: {WEBHOOK_URL[:30]}...")
    print("-" * 50)
    
    # å¯åŠ¨æ—¶å…ˆå‘ä¸€æ¡æµ‹è¯•æ¶ˆæ¯ï¼Œç¡®è®¤é…ç½®æ­£ç¡®
    # controller.send_feishu_alert("ç³»ç»Ÿå¯åŠ¨", "Batch Manager å·²ä¸Šçº¿ï¼Œå¼€å§‹ç›‘æ§ä»»åŠ¡ã€‚")

    try:
        while True:
            controller.run_cycle()
            time.sleep(CHECK_INTERVAL)
    except KeyboardInterrupt:
        print("\nğŸ›‘ Manager stopped by user.")
        controller._save_db()
